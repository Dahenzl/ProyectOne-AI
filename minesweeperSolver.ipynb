{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid detected at region: (113, 320, 499, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Davicito\\OneDrive\\Documentos\\Universidad\\Noveno Semestre\\IA\\Parcial 1\\.venv\\lib\\site-packages\\easyocr\\detection.py:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "c:\\Users\\Davicito\\OneDrive\\Documentos\\Universidad\\Noveno Semestre\\IA\\Parcial 1\\.venv\\lib\\site-packages\\easyocr\\recognition.py:169: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  1 -1 -1 -1 -1 -1]\n",
      " [ 0  0  0  2 -1 -1 -1 -1 -1]\n",
      " [ 0  0  0  2 -1 -1 -1 -1 -1]\n",
      " [ 0  0  0  1  1  1  1 -1 -1]\n",
      " [ 0  0  0  0  0  0  1 -1 -1]\n",
      " [ 0  0  0  0  0  0  2  1 -1]\n",
      " [ 0  0  0  0  0  0  0  2  1]\n",
      " [ 0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "import pyautogui\n",
    "import cv2\n",
    "import numpy as np\n",
    "import easyocr\n",
    "\n",
    "# Step 1: Take a screenshot of the left middle of the screen\n",
    "def take_screenshot(region):\n",
    "    screenshot = pyautogui.screenshot(region=region)\n",
    "    screenshot = np.array(screenshot)\n",
    "    return cv2.cvtColor(screenshot, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# Step 2: Automatically detect the grid\n",
    "def detect_grid(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    edged = cv2.Canny(blurred, 30, 150)\n",
    "\n",
    "    # Find contours in the edge map\n",
    "    contours, _ = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Loop over the contours to find the grid\n",
    "    for contour in contours:\n",
    "        # Get the bounding box for each contour\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        \n",
    "        # Assuming the grid is roughly square-shaped and larger than a threshold size\n",
    "        aspect_ratio = w / float(h)\n",
    "        if 0.9 <= aspect_ratio <= 1.1 and w > 100 and h > 100:\n",
    "            return image[int(y*1.05):int(y*0.95)+h, int(x*1.125):int(x*0.875)+w], (x, y, w, h)\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "# Step 3: Convert the grid into a matrix\n",
    "def grid_to_matrix(grid):\n",
    "    reader = easyocr.Reader(['en'])\n",
    "    grid_size = 9\n",
    "    cell_width = grid.shape[1] // grid_size\n",
    "    cell_height = grid.shape[0] // grid_size\n",
    "    matrix = np.zeros((grid_size, grid_size), dtype=int)\n",
    "    for row in range(grid_size):\n",
    "        for col in range(grid_size):\n",
    "            # Calculate the coordinates of the cell\n",
    "            x_start = col * cell_width\n",
    "            y_start = row * cell_height\n",
    "            x_end = (col + 1) * cell_width\n",
    "            y_end = (row + 1) * cell_height\n",
    "\n",
    "            # Crop the cell from the image\n",
    "            cell = grid[y_start:y_end, x_start:x_end]\n",
    "\n",
    "            # Check the color of the cell\n",
    "            mean_color = np.mean(cell)\n",
    "\n",
    "            if mean_color > 150:  # If the cell is predominantly white\n",
    "                matrix[row, col] = 0\n",
    "            else:  # If the cell is predominantly black\n",
    "                result = reader.readtext(cell, detail=0)\n",
    "                if result:\n",
    "                    matrix[row, col] = int(result[0])\n",
    "                else:\n",
    "                    matrix[row, col] = -1\n",
    "    return matrix\n",
    "    \n",
    "    \n",
    "    \n",
    "# Define the region for the left middle of the screen\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "region = (0, 0, screen_width // 2, screen_height)\n",
    "\n",
    "# Take the screenshot\n",
    "screenshot = take_screenshot(region)\n",
    "\n",
    "# Detect the grid\n",
    "grid, grid_region = detect_grid(screenshot)\n",
    "\n",
    "if grid is not None:\n",
    "    # Save the detected grid image to verify\n",
    "    print(f\"Grid detected at region: {grid_region}\")\n",
    "    cv2.imwrite(\"grid.png\", grid)\n",
    "    # Convert the grid into a matrix\n",
    "    matrix = grid_to_matrix(grid)\n",
    "    print(matrix)\n",
    "else:\n",
    "    print(\"No grid detected\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
